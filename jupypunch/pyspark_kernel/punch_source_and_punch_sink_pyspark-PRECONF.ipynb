{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3549b56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/01 10:27:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "INFO:SparkMonitorKernel:Client Connected ('127.0.0.1', 34270)\n"
     ]
    }
   ],
   "source": [
    "%punch_spark_session -f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe957d60",
   "metadata": {},
   "source": [
    "### Generate data to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4771df25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is available in df variable.\n",
      "Execution time: 0:00:01.785079\n"
     ]
    }
   ],
   "source": [
    "%%punch_source --type generator --name df -o\n",
    "messages:\n",
    "  - app: app1\n",
    "    visits: 20\n",
    "  - app: app2\n",
    "    visits: 50\n",
    "  - app: app2\n",
    "    visits: 0\n",
    "  - app: app1\n",
    "    visits: 10000\n",
    "  - app: app3\n",
    "    visits: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d1e711d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(app='app1', visits=20), Row(app='app2', visits=50)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b56701c",
   "metadata": {},
   "source": [
    "### ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6a085cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved.\n",
      "Execution time: 0:00:07.038279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%punch_sink --type elasticsearch -df df\n",
    "index:\n",
    "    type: constant\n",
    "    value: index-pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef53a5ef",
   "metadata": {},
   "source": [
    "#####  Fetch data from elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e03603a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is available in out variable.\n",
      "Execution time: 0:00:01.558305\n"
     ]
    }
   ],
   "source": [
    "%%punch_source --type elasticsearch --name out -o\n",
    "index: index-pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42203383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- app: string (nullable = true)\n",
      " |-- visits: long (nullable = true)\n",
      "\n",
      "None\n",
      "+----+------+\n",
      "| app|visits|\n",
      "+----+------+\n",
      "|app2|     0|\n",
      "|app1| 10000|\n",
      "|app3|   100|\n",
      "|app1|    20|\n",
      "|app2|    50|\n",
      "|app2|     0|\n",
      "|app1| 10000|\n",
      "|app3|   100|\n",
      "|app1|    20|\n",
      "|app2|    50|\n",
      "|app1|    20|\n",
      "|app2|    50|\n",
      "|app2|     0|\n",
      "|app1| 10000|\n",
      "|app3|   100|\n",
      "|app2|     0|\n",
      "|app1| 10000|\n",
      "|app3|   100|\n",
      "|app1|    20|\n",
      "|app2|    50|\n",
      "+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(out.printSchema())\n",
    "out.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed8e084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb5bf4",
   "metadata": {},
   "source": [
    "### Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572d045",
   "metadata": {},
   "source": [
    "##### Save to kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b28c593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved.\n",
      "Execution time: 0:00:00.784325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%punch_sink --type kafka -df df\n",
    "topic: topic-pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08833eff",
   "metadata": {},
   "source": [
    "### Fetch data from kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce857931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is available in out variable.\n",
      "Execution time: 0:00:00.055489\n"
     ]
    }
   ],
   "source": [
    "%%punch_source --type kafka --name out -o\n",
    "topic: topic-pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e702afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-------------+---------+------+--------------------+-------------+\n",
      "| key|               value|        topic|partition|offset|           timestamp|timestampType|\n",
      "+----+--------------------+-------------+---------+------+--------------------+-------------+\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|     0|2023-02-01 09:38:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|     1|2023-02-01 09:38:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|     2|2023-02-01 09:38:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|     3|2023-02-01 09:38:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|     4|2023-02-01 09:38:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|     5|2023-02-01 09:50:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|     6|2023-02-01 09:50:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|     7|2023-02-01 09:50:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|     8|2023-02-01 09:50:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|     9|2023-02-01 09:50:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|    10|2023-02-01 10:02:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|    11|2023-02-01 10:02:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|    12|2023-02-01 10:02:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|    13|2023-02-01 10:02:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|    14|2023-02-01 10:02:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|    15|2023-02-01 10:25:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|    16|2023-02-01 10:25:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|    17|2023-02-01 10:25:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|    18|2023-02-01 10:25:...|            0|\n",
      "|null|[7B 22 61 70 70 2...|topic-pyspark|        0|    19|2023-02-01 10:25:...|            0|\n",
      "+----+--------------------+-------------+---------+------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(out.printSchema())\n",
    "out.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39e88b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "del out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af9000a",
   "metadata": {},
   "source": [
    "### File (s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fc5c73",
   "metadata": {},
   "source": [
    "### csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4981ec17",
   "metadata": {},
   "source": [
    "##### Save to file in s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08ebdca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/01 10:32:21 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "Data saved.\n",
      "Execution time: 0:00:00.226006\n"
     ]
    }
   ],
   "source": [
    "%%punch_sink --type file -df df\n",
    "options:\n",
    "    header: True\n",
    "format: csv\n",
    "path: s3a://default/pyspark/csv\n",
    "save_mode: Overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df039930",
   "metadata": {},
   "source": [
    "##### Recover data from s3 (file node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ad31e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is available in out variable.\n",
      "Execution time: 0:00:00.118294\n"
     ]
    }
   ],
   "source": [
    "%%punch_source --type file --name out -o \n",
    "format: csv\n",
    "options:\n",
    "  header: true\n",
    "path: s3a://default/pyspark/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a517dd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- app: string (nullable = true)\n",
      " |-- visits: string (nullable = true)\n",
      "\n",
      "None\n",
      "+----+------+\n",
      "| app|visits|\n",
      "+----+------+\n",
      "|app2|     0|\n",
      "|app1| 10000|\n",
      "|app3|   100|\n",
      "|app1|    20|\n",
      "|app2|    50|\n",
      "+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(out.printSchema())\n",
    "out.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d662e04e",
   "metadata": {},
   "source": [
    "### parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9baa477",
   "metadata": {},
   "source": [
    "##### Save to file in s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57fae913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved.\n",
      "Execution time: 0:00:00.218731\n"
     ]
    }
   ],
   "source": [
    "%%punch_sink --type file -df df\n",
    "format: parquet\n",
    "path: s3a://default/pyspark/parquet\n",
    "save_mode: Overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045a8f7",
   "metadata": {},
   "source": [
    "##### Recover data from s3 (file node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "812b818c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is available in out variable.\n",
      "Execution time: 0:00:00.088897\n"
     ]
    }
   ],
   "source": [
    "%%punch_source --type file --name out -o \n",
    "format: parquet\n",
    "path: s3a://default/pyspark/parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ba38b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- app: string (nullable = true)\n",
      " |-- visits: integer (nullable = true)\n",
      "\n",
      "None\n",
      "+----+------+\n",
      "| app|visits|\n",
      "+----+------+\n",
      "|app2|     0|\n",
      "|app1| 10000|\n",
      "|app3|   100|\n",
      "|app1|    20|\n",
      "|app2|    50|\n",
      "+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(out.printSchema())\n",
    "out.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370a276",
   "metadata": {},
   "source": [
    "### json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19d4b57",
   "metadata": {},
   "source": [
    "##### Save to file in s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fa3e094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/01 10:32:39 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "Data saved.\n",
      "Execution time: 0:00:00.211318\n"
     ]
    }
   ],
   "source": [
    "%%punch_sink --type file -df df\n",
    "format: json\n",
    "path: s3a://default/pyspark/json\n",
    "save_mode: Overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db797a9",
   "metadata": {},
   "source": [
    "##### Recover data from s3 (file node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da261e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is available in out variable.\n",
      "Execution time: 0:00:00.086513\n"
     ]
    }
   ],
   "source": [
    "%%punch_source --type file --name out -o \n",
    "format: json\n",
    "path: s3a://default/pyspark/json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "564a2abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- app: string (nullable = true)\n",
      " |-- visits: long (nullable = true)\n",
      "\n",
      "None\n",
      "+----+------+\n",
      "| app|visits|\n",
      "+----+------+\n",
      "|app2|     0|\n",
      "|app1| 10000|\n",
      "|app3|   100|\n",
      "|app1|    20|\n",
      "|app2|    50|\n",
      "+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(out.printSchema())\n",
    "out.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f169764b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Punch Pyspark",
   "language": "python",
   "name": "python3_punch_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1bfdf5a20b6fad5a24b66fafe35178c338447a5fbc205b80b5a132f6d64d4f63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
