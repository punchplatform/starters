{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f88ea0da",
   "metadata": {},
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d09ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "++ java -Xmx1g -Xms256m -Dlog4j.configurationFile=/punch/conf/log4j2/log4j2-stdout.xml -cp /punch/resourcectl.jar com.github.punchplatform.resourcectl.ResourceCtl -u http://artifacts-server.artifacts-server:4245/ download -r model:models:isblue:1.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource model:models:isblue:1.0.0 downloaded to /usr/share/punch/artifacts/models/isblue/1.0.0/isblue_1.0.0.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "Jupyter.notebook.session.restart({kernel_name: 'python3_punch_pyspark'})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%punch_dependencies\n",
    "model:io.models:isblue_pyspark:1.0.0\n",
    "additional-pex:io.models:isblue_pyspark_pex:1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6059cff5",
   "metadata": {},
   "source": [
    "### Get model in a specified path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "936864cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: --override\n"
     ]
    }
   ],
   "source": [
    "%punch_get_model --model io.models:isblue_pyspark:1.0.0 --output model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7582dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/02 08:55:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "INFO:SparkMonitorKernel:Client Connected ('127.0.0.1', 53166)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is available in data variable.\n"
     ]
    }
   ],
   "source": [
    "%%punch_source --type generator --name data -o\n",
    "messages:\n",
    "          - color: red\n",
    "          - color: blue\n",
    "          - color: green\n",
    "          - color: yellow\n",
    "          - color: black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45474cb",
   "metadata": {},
   "source": [
    "### Datascientist loads its model with the appropriate function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2165199e",
   "metadata": {},
   "source": [
    "##### Load model as spark_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6c2479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/21 14:12:21 WARNING mlflow.pyfunc: Calling `spark_udf()` with `env_manager=\"local\"` does not recreate the same environment that was used during training, which may lead to errors or inaccurate predictions. We recommend specifying `env_manager=\"conda\"`, which automatically recreates the environment that was used to train the model and performs inference in the recreated environment.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "__spark_session = SparkSession.builder.getOrCreate()\n",
    "isblue = mlflow.pyfunc.spark_udf(spark=__spark_session, model_uri=model_path, result_type=\"double\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc9a6f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "| color|prediction|\n",
      "+------+----------+\n",
      "|   red|       0.0|\n",
      "|  blue|       1.0|\n",
      "| green|       0.0|\n",
      "|yellow|       0.0|\n",
      "| black|       0.0|\n",
      "+------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import struct\n",
    "\n",
    "udf_inputs = struct(*(data.columns))\n",
    "data.withColumn(\"prediction\", isblue(udf_inputs)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a8c4db",
   "metadata": {},
   "source": [
    "### Load model with pyspark pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ebb2cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "2022/10/21 14:12:45 WARNING mlflow.pyfunc: Calling `spark_udf()` with `env_manager=\"local\"` does not recreate the same environment that was used during training, which may lead to errors or inaccurate predictions. We recommend specifying `env_manager=\"conda\"`, which automatically recreates the environment that was used to train the model and performs inference in the recreated environment.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: udf(color), dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.pandas as pd\n",
    "from pyspark.pandas.mlflow import load_model\n",
    "\n",
    "isblue = load_model(model_uri=model_path, predict_type=\"double\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "isblue.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f48240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Punch Pyspark",
   "language": "python",
   "name": "python3_punch_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
